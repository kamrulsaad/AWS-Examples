{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%pip install nltk\n",
    "%pip install rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "reference1 = 'the cat is on the mat'\n",
    "reference2 = 'there is a cat on the mat'\n",
    "references = [\n",
    "    nltk.word_tokenize(reference1),\n",
    "    nltk.word_tokenize(reference2)\n",
    "]\n",
    "# Candidate translation\n",
    "# candidate_sentence = 'the cat is on the mat' # extact match\n",
    "candidate_sentence = 'the cat sat on the mat' # similar match\n",
    "candidate = nltk.word_tokenize(candidate_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate BLEU score with smoothing\n",
    "smoothie = SmoothingFunction().method4\n",
    "bleu_score = sentence_bleu(\n",
    "    references,\n",
    "    candidate,\n",
    "    smoothing_function=smoothie\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Candidate Sentence: {candidate_sentence}\")\n",
    "print(f\"BLEU score: {bleu_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.translate.meteor_score import meteor_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "nltk.download('wordnet')  # Required for METEOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate METEOR score\n",
    "meteor = meteor_score(references, candidate)\n",
    "\n",
    "print(f\"Candidate Sentence: {candidate}\")\n",
    "print(f\"METEOR score: {meteor:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "references = [\n",
    "    'the cat is on the mat',\n",
    "    'there is a cat on the mat'\n",
    "]\n",
    "# Candidate translation\n",
    "# candidate_sentence = 'the cat is on the mat' # extact match\n",
    "candidate = 'the cat sat on the mat' # similar match\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "scores = scorer.score(' '.join(references), candidate)\n",
    "\n",
    "print(f\"ROUGE-1 score: {scores['rouge1'].fmeasure:.4f}\")\n",
    "print(f\"ROUGE-L score: {scores['rougeL'].fmeasure:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
